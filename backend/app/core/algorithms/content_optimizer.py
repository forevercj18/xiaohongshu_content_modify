"""
å†…å®¹ä¼˜åŒ–å™¨ - è°éŸ³è¯æ›¿æ¢å’Œå†…å®¹ä¼˜åŒ–
"""
import re
import random
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session

from app.models.database import OriginalWord, HomophoneReplacement
from app.core.algorithms.emoji_inserter import EmojiInserter


class ContentOptimizer:
    """å†…å®¹ä¼˜åŒ–å™¨"""
    
    def __init__(self, db: Session):
        self.db = db
        self.homophone_mappings = self._load_homophone_mappings()
        self.emoji_inserter = EmojiInserter(db)
    
    def _load_homophone_mappings(self) -> Dict[str, List[Dict]]:
        """åŠ è½½è°éŸ³è¯æ˜ å°„"""
        mappings = {}
        
        # æŸ¥è¯¢æ‰€æœ‰å¯ç”¨çš„è°éŸ³è¯æ›¿æ¢
        replacements = self.db.query(HomophoneReplacement).join(OriginalWord).filter(
            HomophoneReplacement.status == 1,
            OriginalWord.status == 1
        ).all()
        
        for replacement in replacements:
            original_word = replacement.original.word
            if original_word not in mappings:
                mappings[original_word] = []
            
            mappings[original_word].append({
                "replacement": replacement.replacement_word,
                "type": replacement.replacement_type,
                "priority": replacement.priority,
                "confidence": replacement.confidence_score,
                "usage_count": replacement.usage_count,
                "id": replacement.id
            })
        
        return mappings
    
    async def optimize_content(self, content: str, apply_suggestions: List[str] = None) -> Dict[str, Any]:
        """ä¼˜åŒ–å†…å®¹"""
        optimized_content = content
        applied_changes = []
        
        # åº”ç”¨è°éŸ³è¯æ›¿æ¢
        if not apply_suggestions or "homophone_replacement" in apply_suggestions:
            optimized_content, changes = self._apply_homophone_replacements(optimized_content)
            applied_changes.extend(changes)
        
        # åº”ç”¨å…¶ä»–ä¼˜åŒ–
        if not apply_suggestions or "structure_optimization" in apply_suggestions:
            optimized_content, changes = self._apply_structure_optimization(optimized_content)
            applied_changes.extend(changes)
        
        # åº”ç”¨è¡¨æƒ…ç¬¦å·ä¼˜åŒ–
        if not apply_suggestions or "emoji_optimization" in apply_suggestions:
            optimized_content, changes = self.emoji_inserter.analyze_content_and_insert_emojis(optimized_content)
            applied_changes.extend(changes)
        
        # è®¡ç®—ä¼˜åŒ–åçš„åˆ†æ•°
        from app.core.algorithms.content_analyzer import ContentAnalyzer
        analyzer = ContentAnalyzer(self.db)
        
        # åˆ†æåŸå§‹å†…å®¹
        original_analysis = await analyzer.analyze_content(content)
        original_score = original_analysis["score"]
        
        # åˆ†æä¼˜åŒ–åå†…å®¹
        optimized_analysis = await analyzer.analyze_content(optimized_content)
        optimized_score = optimized_analysis["score"]
        
        # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
        self._update_usage_statistics(applied_changes)
        
        return {
            "optimized_content": optimized_content,
            "applied_changes": applied_changes,
            "score_before": original_score,
            "score_after": optimized_score,
            "score_improvement": optimized_score - original_score
        }
    
    def _apply_homophone_replacements(self, content: str) -> tuple[str, List[Dict]]:
        """åº”ç”¨è°éŸ³è¯æ›¿æ¢"""
        optimized_content = content
        applied_changes = []
        
        for original_word, replacements in self.homophone_mappings.items():
            if original_word in optimized_content:
                # é€‰æ‹©æ›¿æ¢è¯
                replacement_info = self._select_replacement(replacements)
                if replacement_info:
                    replacement_word = replacement_info["replacement"]
                    
                    # æ‰§è¡Œæ›¿æ¢
                    old_content = optimized_content
                    optimized_content = optimized_content.replace(original_word, replacement_word)
                    
                    if old_content != optimized_content:
                        applied_changes.append({
                            "type": "homophone_replacement",
                            "original_word": original_word,
                            "replacement_word": replacement_word,
                            "replacement_type": replacement_info["type"],
                            "replacement_id": replacement_info["id"],
                            "positions": self._find_word_positions(old_content, original_word)
                        })
        
        return optimized_content, applied_changes
    
    def _select_replacement(self, replacements: List[Dict]) -> Optional[Dict]:
        """é€‰æ‹©è°éŸ³è¯æ›¿æ¢"""
        if not replacements:
            return None
        
        # ä¼˜å…ˆé€‰æ‹©priority=1çš„è¯æ±‡
        priority_words = [r for r in replacements if r["priority"] == 1]
        if priority_words:
            return random.choice(priority_words)
        
        # å¦‚æœæ²¡æœ‰é«˜ä¼˜å…ˆçº§è¯æ±‡ï¼ŒæŒ‰ç½®ä¿¡åº¦åŠ æƒéšæœºé€‰æ‹©
        weights = [r["confidence"] for r in replacements]
        return random.choices(replacements, weights=weights)[0]
    
    def _find_word_positions(self, content: str, word: str) -> List[int]:
        """æŸ¥æ‰¾è¯æ±‡åœ¨å†…å®¹ä¸­çš„ä½ç½®"""
        positions = []
        start = 0
        while True:
            pos = content.find(word, start)
            if pos == -1:
                break
            positions.append(pos)
            start = pos + 1
        return positions
    
    def _apply_structure_optimization(self, content: str) -> tuple[str, List[Dict]]:
        """åº”ç”¨ç»“æ„ä¼˜åŒ–"""
        optimized_content = content
        applied_changes = []
        
        # æ®µè½ä¼˜åŒ–
        if len(content) > 200 and '\n' not in content:
            # ç®€å•çš„æ®µè½åˆ†å‰²ï¼ˆåœ¨å¥å·ååˆ†å‰²ï¼‰
            sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', content)
            if len(sentences) > 3:
                # æ¯2-3å¥ç»„æˆä¸€ä¸ªæ®µè½
                paragraphs = []
                current_paragraph = ""
                sentence_count = 0
                
                for i in range(0, len(sentences) - 1, 2):
                    if i + 1 < len(sentences):
                        sentence = sentences[i] + sentences[i + 1]
                        current_paragraph += sentence
                        sentence_count += 1
                        
                        if sentence_count >= 2 or len(current_paragraph) > 100:
                            paragraphs.append(current_paragraph.strip())
                            current_paragraph = ""
                            sentence_count = 0
                
                if current_paragraph.strip():
                    paragraphs.append(current_paragraph.strip())
                
                if len(paragraphs) > 1:
                    optimized_content = '\n\n'.join(paragraphs)
                    applied_changes.append({
                        "type": "paragraph_structure",
                        "description": f"å°†é•¿æ®µè½åˆ†è§£ä¸º {len(paragraphs)} ä¸ªæ®µè½",
                        "paragraphs_count": len(paragraphs)
                    })
        
        # è¡¨æƒ…ç¬¦å·ä¼˜åŒ–ï¼ˆç®€å•ç¤ºä¾‹ï¼‰
        emoji_count = len(re.findall(r'[ğŸ˜€-ğŸ™]', content))
        if emoji_count == 0 and len(content) > 50:
            # åœ¨å†…å®¹æœ«å°¾æ·»åŠ é€‚å½“çš„è¡¨æƒ…ç¬¦å·
            positive_emojis = ['âœ¨', 'ğŸ‘', 'ğŸ’«', 'ğŸŒŸ', 'ğŸ˜Š']
            selected_emoji = random.choice(positive_emojis)
            optimized_content += f" {selected_emoji}"
            
            applied_changes.append({
                "type": "emoji_addition",
                "description": f"æ·»åŠ è¡¨æƒ…ç¬¦å·: {selected_emoji}",
                "emoji": selected_emoji
            })
        
        return optimized_content, applied_changes
    
    def _update_usage_statistics(self, applied_changes: List[Dict]):
        """æ›´æ–°ä½¿ç”¨ç»Ÿè®¡"""
        for change in applied_changes:
            if change["type"] == "homophone_replacement":
                replacement_id = change.get("replacement_id")
                if replacement_id:
                    # æ›´æ–°è°éŸ³è¯ä½¿ç”¨æ¬¡æ•°
                    replacement = self.db.query(HomophoneReplacement).filter(
                        HomophoneReplacement.id == replacement_id
                    ).first()
                    if replacement:
                        replacement.usage_count += 1
        
        try:
            self.db.commit()
        except Exception as e:
            self.db.rollback()
            print(f"æ›´æ–°ä½¿ç”¨ç»Ÿè®¡å¤±è´¥: {e}")
    
    def get_replacement_suggestions(self, word: str) -> List[Dict]:
        """è·å–æŒ‡å®šè¯æ±‡çš„æ›¿æ¢å»ºè®®"""
        if word in self.homophone_mappings:
            replacements = self.homophone_mappings[word]
            return sorted(replacements, key=lambda x: (x["priority"], x["confidence"]), reverse=True)
        return []